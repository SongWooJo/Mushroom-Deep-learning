{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDnIlyG/phzS1vcb63nZIG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","#cd command needs '%' not '!', while other Unix commands need '!'\n","%cd ./drive/My\\ Drive/summer\\ vacation 3\n","!pwd\n","!ls -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdrfZci3Ui-N","executionInfo":{"status":"ok","timestamp":1723522931279,"user_tz":-540,"elapsed":18843,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"32aa3ff4-1afc-4a3b-c41e-fba18db096ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/summer vacation 3\n","/content/drive/My Drive/summer vacation 3\n","total 1819\n","-rw------- 1 root root   19101 Aug 13 02:07 'chatgpt는 바보다.ipynb'\n","drwx------ 2 root root    4096 Aug  3 09:25  data\n","-rw------- 1 root root   17852 Aug  9 09:58  LOL_data_model.ipynb\n","-rw------- 1 root root   29690 Aug 12 11:02 'mushroom CNN.ipynb'\n","-rw------- 1 root root 1790805 Aug 12 11:38 '버섯데이터 전이학습.ipynb'\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os"],"metadata":{"id":"JPzkpysSgsLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import cv2\n","import random\n","import torch.optim as optim\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import warnings\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, random_split, Dataset\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","from PIL import Image\n","from transformers import AutoFeatureExtractor, SwinForImageClassification\n","from torchvision import models\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"8094QOtGgxXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(20),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"Y3NwKT9mhRNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_paths = []\n","\n","for relative_path1 in os.listdir('/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms'):\n","    for relative_path2 in tqdm(os.listdir(os.path.join('/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms', relative_path1))):\n","#         print(relative_path2)\n","        full_path = os.path.join('/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms', relative_path1, relative_path2)\n","        image_paths.append(full_path)\n","\n","print(len(image_paths))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFJQSEoehWPZ","executionInfo":{"status":"ok","timestamp":1723465070108,"user_tz":-540,"elapsed":809,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"2bb713b4-b69c-43aa-b0ad-6c956b0a966e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 750/750 [00:00<00:00, 293526.92it/s]\n","100%|██████████| 364/364 [00:00<00:00, 146730.10it/s]\n","100%|██████████| 1148/1148 [00:00<00:00, 294841.77it/s]\n","100%|██████████| 311/311 [00:00<00:00, 163646.79it/s]\n","100%|██████████| 1563/1563 [00:00<00:00, 394327.65it/s]\n","100%|██████████| 1073/1073 [00:00<00:00, 233464.14it/s]\n","100%|██████████| 836/836 [00:00<00:00, 214513.53it/s]\n","100%|██████████| 316/316 [00:00<00:00, 284909.73it/s]\n","100%|██████████| 353/353 [00:00<00:00, 263356.33it/s]"]},{"output_type":"stream","name":"stdout","text":["6714\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["image_paths[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYVztiq9hkZz","executionInfo":{"status":"ok","timestamp":1723465092327,"user_tz":-540,"elapsed":306,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"c85ba2d1-c18e-4e8e-ad77-ecd776bc367b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Amanita/079_6ZA8RSmhL-k.jpg',\n"," '/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Amanita/080_Ye1LzJ2aCoI.jpg',\n"," '/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Amanita/016_S-Z6ZIo2G3k.jpg',\n"," '/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Amanita/046_55Y02Q5s8MQ.jpg',\n"," '/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Amanita/100_w6tcyq1AMVk.jpg']"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["test_image_paths = random.sample(image_paths, k=int(len(image_paths) * 0.15))\n","train_image_paths = [x for x in image_paths if x not in test_image_paths]\n","print(len(test_image_paths), len(train_image_paths))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehoB2Zhdhnao","executionInfo":{"status":"ok","timestamp":1723465105729,"user_tz":-540,"elapsed":338,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"639c5ab3-c47f-4ce4-e309-c780e6db4a7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1007 5707\n"]}]},{"cell_type":"code","source":["class_name = sorted(os.listdir('/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms'))\n","print(class_name)\n","class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_name)}\n","print(class_to_idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d70juSNthr1X","executionInfo":{"status":"ok","timestamp":1723465749803,"user_tz":-540,"elapsed":325,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"523328ca-51a0-405b-d70f-a0c299ca8fb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Agaricus', 'Amanita', 'Boletus', 'Cortinarius', 'Entoloma', 'Hygrocybe', 'Lactarius', 'Russula', 'Suillus']\n","{'Agaricus': 0, 'Amanita': 1, 'Boletus': 2, 'Cortinarius': 3, 'Entoloma': 4, 'Hygrocybe': 5, 'Lactarius': 6, 'Russula': 7, 'Suillus': 8}\n"]}]},{"cell_type":"code","source":["class MushroomDataset(Dataset):\n","    def __init__(self, image_paths, transform=None):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        try:\n","            label = class_to_idx[self.image_paths[idx].split('/')[-2]]\n","            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n","#             image = np.clip(image, 0, 1)\n","#             image = Image.fromarray((image * 255).astype(np.uint8))\n","            if self.transform is not None:\n","                image = self.transform(image)\n","            return image, label\n","        except:\n","            image = Image.open('/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Agaricus/000_ePQknW8cTp8.jpg').convert(\"RGB\")\n","            label = 0\n","            if self.transform is not None:\n","                image = self.transform(image)\n","            return image, label\n","\n","    def __len__(self):\n","        return len(self.image_paths)"],"metadata":{"id":"gKdQU_sohxkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = MushroomDataset(train_image_paths, transform=train_transform)\n","test_data = MushroomDataset(test_image_paths, transform=test_transform)\n","\n","print(len(train_data), len(test_data))\n","\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n","\n","print(train_data.class_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"51hk9lRLh4vC","executionInfo":{"status":"error","timestamp":1723467215026,"user_tz":-540,"elapsed":312,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"fb414572-8a09-426b-ca7b-52cd711aa51d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5707 1007\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'MushroomDataset' object has no attribute 'class_indices'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-7750d5942bd0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'MushroomDataset' object has no attribute 'class_indices'"]}]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"nbFsTVOxh7_8","executionInfo":{"status":"ok","timestamp":1723465217614,"user_tz":-540,"elapsed":5,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"2e53e6d9-15e1-4e45-ff0d-0cccb25eb546"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["label_dict = {}\n","for path in train_image_paths:\n","    label_name = path.split('/')[-2]\n","    label_dict[class_to_idx[label_name]] = label_dict.get(class_to_idx[label_name], 0) + 1\n","print(sorted(label_dict.items()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGED1cZoh-jS","executionInfo":{"status":"ok","timestamp":1723465218941,"user_tz":-540,"elapsed":3,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"2e776a03-58d1-46d3-b296-0a6b7f21990b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 293), (1, 646), (2, 912), (3, 713), (4, 306), (5, 264), (6, 1342), (7, 962), (8, 269)]\n"]}]},{"cell_type":"code","source":["num = []\n","weights = []\n","final_weights = []\n","for i in range(9):\n","    num.append(label_dict[i])\n","for i in range(9):\n","    weights.append(1 / num[i] * sum(num))\n","for i in range(9):\n","    final_weights.append(weights[i] / max(weights))\n","print(final_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LvkOHfMGiF_5","executionInfo":{"status":"ok","timestamp":1723465230917,"user_tz":-540,"elapsed":339,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"53b52f1f-762d-4636-ea83-df3b7262104a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.9010238907849829, 0.4086687306501548, 0.28947368421052627, 0.3702664796633941, 0.8627450980392156, 1.0, 0.19672131147540983, 0.27442827442827444, 0.9814126394052044]\n"]}]},{"cell_type":"code","source":["num_classes = 9\n","criterion = nn.CrossEntropyLoss().to(device)"],"metadata":{"id":"7Sa6BNxUiKxr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["분류"],"metadata":{"id":"f35SDjELbQMO"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# 이미지 경로\n","training_dir = \"/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms\"\n","\n","# 전체 이미지를 1/255로 스케일 조정\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","# 훈련 이미지를 244*244 크기로 다시 조정하고, 레이블을 부여한 배치 데이터 생성\n","train_generator = train_datagen.flow_from_directory(\n","    training_dir,\n","    target_size=(244, 244),\n","    # 버섯을 구분하는 다중 클래스 분류이므로 categorical 사용\n","    class_mode='categorical'\n",")\n","\n","# 레이블 확인\n","print(train_generator.class_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dTfN-wLn3MI","executionInfo":{"status":"ok","timestamp":1723522964327,"user_tz":-540,"elapsed":9774,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"013137b7-656a-4822-ebd5-3d2ea957a3c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6714 images belonging to 9 classes.\n","{'Agaricus': 0, 'Amanita': 1, 'Boletus': 2, 'Cortinarius': 3, 'Entoloma': 4, 'Hygrocybe': 5, 'Lactarius': 6, 'Russula': 7, 'Suillus': 8}\n"]}]},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","    # 입력값은 244*244 크기의 RGB 이미지\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(244, 244, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    # 분류 대상이 9개이므로 아홉개의 뉴런을 사용\n","    tf.keras.layers.Dense(9, activation='sigmoid')\n","])"],"metadata":{"id":"vA1JnwCAibg_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"az2F_yHrobzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 시작\n","model.fit(train_generator, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hGvf1yPTpIFk","executionInfo":{"status":"error","timestamp":1723525436852,"user_tz":-540,"elapsed":200185,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"6b1273b5-48ef-4ff5-9927-222b9c0b0501"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m 83/210\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5:00\u001b[0m 2s/step - accuracy: 0.3498 - loss: 1.8102"]},{"output_type":"error","ename":"UnknownError","evalue":"Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nOSError: image file is truncated (92 bytes not processed)\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\", line 292, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2156, in resize\n    self.load()\n\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 266, in load\n    raise OSError(msg)\n\nOSError: image file is truncated (92 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2656]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a8635f5b4ccd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 훈련 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nOSError: image file is truncated (92 bytes not processed)\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\", line 292, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2156, in resize\n    self.load()\n\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\", line 266, in load\n    raise OSError(msg)\n\nOSError: image file is truncated (92 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2656]"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from keras.preprocessing import image"],"metadata":{"id":"nmeN3VJ9-30L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트 예시"],"metadata":{"id":"R2mq0mgzbUIb"}},{"cell_type":"code","source":["# 테스트 이미지 가져오기\n","sample_images = [\n","    ['/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Agaricus/000_ePQknW8cTp8.jpg'],\n","    ['/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Amanita/000_ePQknW8cTp8.jpg'],\n","    ['/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms/Boletus/000_ePQknW8cTp8.jpg']\n","    ]"],"metadata":{"id":"BfRtKYXm-7B7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fn in sample_images:\n","    # matplotlib을 이용하여 이미지 출력\n","    plt.imshow(mpimg.imread(fn))\n","    plt.show()\n","\n","    # Keras에 이미지를 300*300 크기로 불러오기\n","    img = tf.keras.utils.load_img(fn, target_size=(300, 300))\n","    # 이미지를 2D 배열로 변환\n","    x = tf.keras.utils.img_to_array(img)\n","    print(\"2D 배열 shape : \", x.shape)\n","    # 모델의 input_shape가 (300, 300, 3)이므로 이 모양으로 변환\n","    x = np.expand_dims(x, axis=0)\n","    print(\"3D 배열 shape : \", x.shape)\n","\n","    classes = model.predict(x)\n","\n","    print(\"모델 출력 : \", classes[0][0])\n","    if (classes[0][0] ==0):\n","        print(fn + \"는 Agaricus입니다.\")\n","    elif (classes[0][0] ==1):\n","        print(fn + \"는 Amanita입니다.\")\n","    elif (classes[0][0] ==2):\n","        print(fn + \"는 Boletus입니다.\")\n","    elif (classes[0][0] ==3):\n","        print(fn + \"는 Cortinarius입니다.\")\n","    elif (classes[0][0] ==4):\n","        print(fn + \"는 Entoloma입니다.\")\n","    elif (classes[0][0] ==5):\n","        print(fn + \"는 Hygrocybe입니다.\")\n","    elif (classes[0][0] ==6):\n","        print(fn + \"는 Lactarius입니다.\")\n","    elif (classes[0][0] ==7):\n","        print(fn + \"는 Russula입니다.\")\n","    else:\n","        print(fn + \"는 Suillus입니다.\")"],"metadata":{"id":"r0Y-DEg8-04r"},"execution_count":null,"outputs":[]}]}