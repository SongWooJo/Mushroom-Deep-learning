{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZjEUuQgZwms0yzL/cj5x8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1cLljSPkbOH","executionInfo":{"status":"ok","timestamp":1723455405728,"user_tz":-540,"elapsed":33416,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"f172f9f4-342b-4651-91ad-b018d7b11a87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/summer vacation 3\n","/content/drive/My Drive/summer vacation 3\n","total 1798\n","drwx------ 2 root root    4096 Aug  3 09:25  data\n","-rw------- 1 root root   17852 Aug  9 09:58  LOL_data_model.ipynb\n","-rw------- 1 root root   26835 Aug 12 09:36 'mushroom CNN.ipynb'\n","-rw------- 1 root root 1791244 Aug 12 09:32 '버섯데이터 전이학습.ipynb'\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","#cd command needs '%' not '!', while other Unix commands need '!'\n","%cd ./drive/My\\ Drive/summer\\ vacation 3\n","!pwd\n","!ls -l"]},{"cell_type":"markdown","source":["DataSet Class"],"metadata":{"id":"lKodu3ZqEVXj"}},{"cell_type":"code","source":["# import libraries\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","\n","import pandas\n","import matplotlib.pyplot as plt"],"metadata":{"id":"GGVUoXbcETxO","executionInfo":{"status":"ok","timestamp":1723455413094,"user_tz":-540,"elapsed":5277,"user":{"displayName":"조성우","userId":"00319176654126796168"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Load Data"],"metadata":{"id":"lCZl5wL5Elt8"}},{"cell_type":"code","source":["# 데이터 경로 설정\n","Mushrooms_dataset_file = '/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms'"],"metadata":{"id":"chUi6xIbEeMe","executionInfo":{"status":"ok","timestamp":1723455413095,"user_tz":-540,"elapsed":3,"user":{"displayName":"조성우","userId":"00319176654126796168"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import os\n","import torch\n","from torchvision import transforms\n","\n","class MushroomDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_files = []\n","        self.labels = []\n","\n","        # Create class to index mapping\n","        self.classes = sorted(os.listdir(root_dir))\n","        self.classes_index = {cls: i for i, cls in enumerate(self.classes)}\n","\n","        # Traverse root directory and collect image paths and labels\n","        for cls_name in self.classes:\n","            cls_dir = os.path.join(root_dir, cls_name)\n","            if os.path.isdir(cls_dir):\n","                for file_name in os.listdir(cls_dir):\n","                    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","                        self.image_files.append(os.path.join(cls_dir, file_name))\n","                        self.labels.append(self.classes_index[cls_name])\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, index):\n","        img_path = self.image_files[index]\n","        label = self.labels[index]\n","\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        target = torch.tensor(label, dtype=torch.long)  # Convert label to tensor\n","\n","        return image, target"],"metadata":{"id":"jEN7e9FE9kK7","executionInfo":{"status":"ok","timestamp":1723455420940,"user_tz":-540,"elapsed":2883,"user":{"displayName":"조성우","userId":"00319176654126796168"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True  # 잘린 이미지 로드 허용\n","\n","import os\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","\n","# 데이터 변환 정의\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# 전체 데이터셋 로드\n","dataset = datasets.ImageFolder(root='/content/drive/MyDrive/summer vacation 3/data/archive/Mushrooms', transform=transform)\n","\n","# 클래스별로 데이터 분할\n","class_indices = {cls: [] for cls in dataset.classes}\n","for idx, (img, label) in enumerate(dataset):\n","    class_indices[dataset.classes[label]].append(idx)\n","\n","train_indices = []\n","test_indices = []\n","\n","# 각 클래스별로 75%-25% 분할\n","for cls, indices in class_indices.items():\n","  n_train = int(len(class_indices) * 0.75)\n","  train_indices.extend(class_indices[:n_train])\n","  test_indices.extend(class_indices[n_train:])\n","\n","# Subset을 이용하여 Train/Test Dataset 생성\n","train_dataset = torch.utils.data.Subset(dataset, train_indices)\n","test_dataset = torch.utils.data.Subset(dataset, test_indices)\n","\n","# DataLoader 생성\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","# 클래스 인덱스 확인\n","classes = sorted(dataset.classes)\n","classes_index = {c: i for i, c in enumerate(classes)}\n","\n","print(classes)\n","print(classes_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"DcRkM0IC8UxB","executionInfo":{"status":"error","timestamp":1723460555537,"user_tz":-540,"elapsed":591944,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"ed881009-f8e6-4f9d-a24f-2e5dd7ff711f"},"execution_count":11,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unhashable type: 'slice'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b2b84e5fb2a0>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mtrain_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0mtest_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"]}]},{"cell_type":"markdown","source":["256x256 크기로 변환, 회전 x"],"metadata":{"id":"ZHQHoeMMRJ3k"}},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","\n","# 변환 정의 (Image Transformation)\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.CenterCrop((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# 전체 데이터셋 로드 (Load Entire Dataset)\n","dataset = datasets.ImageFolder(root=Mushrooms_dataset_file, transform=transform)\n","\n","# 데이터셋 크기 설정 (Set the size of training and testing datasets)\n","train_size = int(0.8 * len(dataset))  # 80% for training\n","test_size = len(dataset) - train_size  # 20% for testing\n","\n","# 데이터셋 분할 (Split Dataset)\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","# 데이터 로더 설정 (Set up DataLoaders)\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","# 클래스 인덱스 확인 (Check Class Indices)\n","classes = sorted(dataset.classes)\n","classes_index = {c: i for i, c in enumerate(classes)}\n","\n","print(classes)\n","print(classes_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mN3ETInDMd65","executionInfo":{"status":"ok","timestamp":1723446164942,"user_tz":-540,"elapsed":926,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"f64f801a-3da6-4d6b-ce7f-c2a3deccbe3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Agaricus', 'Amanita', 'Boletus', 'Cortinarius', 'Entoloma', 'Hygrocybe', 'Lactarius', 'Russula', 'Suillus']\n","{'Agaricus': 0, 'Amanita': 1, 'Boletus': 2, 'Cortinarius': 3, 'Entoloma': 4, 'Hygrocybe': 5, 'Lactarius': 6, 'Russula': 7, 'Suillus': 8}\n"]}]},{"cell_type":"markdown","source":["임의의 각도로 회전(-30~30)"],"metadata":{"id":"o79rtU2iRI1J"}},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# 변환 정의\n","train_transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.RandomRotation(degrees=30),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.RandomRotation(degrees=30),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# 데이터 로드\n","train_dataset = datasets.ImageFolder(root=Mushrooms_dataset_file, transform=train_transform)\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","\n","test_dataset = datasets.ImageFolder(root=Mushrooms_dataset_file, transform=test_transform)\n","test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n","\n","# 클래스 인덱스 확인\n","classes = sorted(train_dataset.classes)\n","classes_index = {c: i for i, c in enumerate(classes)}\n","\n","print(classes)\n","print(classes_index)\n"],"metadata":{"id":"whcLiAFpRTCU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3차원그림 Relu사용, BCELoss 사용, Adam"],"metadata":{"id":"gSx43ElqQB1w"}},{"cell_type":"code","source":["# classifier class\n","\n","class Classifier(nn.Module):\n","\n","    def __init__(self):\n","        # initialise parent pytorch class\n","        super().__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(3*256*256, 100),\n","            nn.LeakyReLU(),\n","\n","            nn.LayerNorm(100),\n","\n","            nn.Linear(100, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        # create loss function\n","        self.loss_function = nn.BCELoss()\n","\n","        # create optimiser, using simple stochastic gradient descent\n","        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.001)\n","\n","        # counter and accumulator for progress\n","        self.counter = 0\n","        self.progress = []\n","\n","        pass\n","\n","\n","    def forward(self, inputs):\n","        # simply run model\n","        inputs = inputs.view(inputs.size(0), -1)\n","        return self.model(inputs)\n","\n","\n","    def train(self, inputs, targets):\n","        # calculate the output of the network\n","        outputs = self.forward(inputs)\n","\n","        targets = targets.float()\n","\n","        # calculate loss\n","        loss = self.loss_function(outputs, targets)\n","\n","        # increase counter and accumulate error every 10\n","        self.counter += 1\n","        if (self.counter % 10 == 0):\n","            self.progress.append(loss.item())\n","            pass\n","        if (self.counter % 10000 == 0):\n","            print(\"counter = \", self.counter)\n","            pass\n","\n","        # zero gradients, perform a backward pass, and update the weights\n","        self.optimiser.zero_grad()\n","        loss.backward()\n","        self.optimiser.step()\n","\n","        pass\n","\n","\n","    def plot_progress(self):\n","        df = pandas.DataFrame(self.progress, columns=['loss'])\n","        df.plot(ylim=(0, 1.0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5))\n","        pass\n","\n","    def evaluate(self, data_loader):\n","        self.eval()\n","        total_loss = 0\n","        correct_predictions = 0\n","        total_samples = 0\n","\n","        with torch.no_grad():\n","            for inputs, targets in data_loader:\n","                outputs = self.forward(inputs)\n","                loss = self.loss_function(outputs, targets)\n","                total_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs, 1)\n","                _, actual = torch.max(targets, 1)\n","                correct_predictions += (predicted == actual).sum().item()\n","                total_samples += targets.size(0)\n","\n","        avg_loss = total_loss / len(data_loader)\n","        accuracy = (correct_predictions / total_samples) * 100\n","        return avg_loss, accuracy\n","\n","    pass"],"metadata":{"id":"rO2s2ig0P99O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3차원, Relu사용, CrossEntropyLoss, Adam"],"metadata":{"id":"_fTvGHHrQu7w"}},{"cell_type":"code","source":["# classifier class\n","\n","class Classifier(nn.Module):\n","\n","    def __init__(self):\n","        # initialise parent pytorch class\n","        super().__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(3*224*224, 1000),\n","            nn.LeakyReLU(),\n","\n","            nn.LayerNorm(1000),\n","\n","            nn.Linear(1000, 10),\n","            nn.Sigmoid()\n","        )\n","\n","        # create loss function\n","        self.loss_function = nn.CrossEntropyLoss()\n","\n","        # create optimiser, using simple stochastic gradient descent\n","        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.001)\n","\n","        # counter and accumulator for progress\n","        self.counter = 0\n","        self.progress = []\n","\n","        pass\n","\n","\n","    def forward(self, inputs):\n","        # simply run model\n","        inputs = inputs.view(inputs.size(0), -1)\n","        return self.model(inputs)\n","\n","\n","    def train(self, inputs, targets):\n","        # calculate the output of the network\n","        outputs = self.forward(inputs)\n","\n","        # calculate loss\n","        loss = self.loss_function(outputs, targets)\n","\n","        # increase counter and accumulate error every 10\n","        self.counter += 1\n","        if (self.counter % 10 == 0):\n","            self.progress.append(loss.item())\n","            pass\n","        if (self.counter % 1000 == 0):\n","            print(\"counter = \", self.counter)\n","            pass\n","\n","        # zero gradients, perform a backward pass, and update the weights\n","        self.optimiser.zero_grad()\n","        loss.backward()\n","        self.optimiser.step()\n","\n","        pass\n","\n","\n","    def plot_progress(self):\n","        df = pandas.DataFrame(self.progress, columns=['loss'])\n","        df.plot(ylim=(0, 1.0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5))\n","        pass\n","\n","    def evaluate(self, data_loader):\n","        self.eval()\n","        total_loss = 0\n","        correct_predictions = 0\n","        total_samples = 0\n","\n","        with torch.no_grad():\n","            for inputs, targets in data_loader:\n","                outputs = self.forward(inputs)\n","                loss = self.loss_function(outputs, targets)\n","                total_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs, 1)\n","                _, actual = torch.max(targets, 1)\n","                correct_predictions += (predicted == actual).sum().item()\n","                total_samples += targets.size(0)\n","\n","        avg_loss = total_loss / len(data_loader)\n","        accuracy = (correct_predictions / total_samples) * 100\n","        return avg_loss, accuracy\n","\n","    pass"],"metadata":{"id":"z13zRiQWQJFI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["학습시키기"],"metadata":{"id":"ThQ9CmSpQHHI"}},{"cell_type":"code","source":["%%time\n","# create neural network\n","\n","C = Classifier()\n","\n","# train neural network\n","epochs = 4\n","\n","for i in range(epochs):\n","    print('training epoch', i+1, \"of\", epochs)\n","    for inputs, targets in train_loader:\n","        C.train(inputs, targets)\n","    # 평가\n","    train_loss, train_accuracy = C.evaluate(train_loader)\n","    test_loss, test_accuracy = C.evaluate(test_loader)\n","\n","    # 결과 출력\n","    print(f'Epoch [{i + 1} / {epochs}], '\n","          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n","          f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"j_XXy9XuNXJ3","executionInfo":{"status":"ok","timestamp":1723435318409,"user_tz":-540,"elapsed":13136,"user":{"displayName":"조성우","userId":"00319176654126796168"}},"outputId":"dd37c32c-6baf-41cf-a346-705c98c6be44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training epoch 1 of 4\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}